{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ComplejidadSintáctica.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMvnResP+yAl7gwo2NyP1ht"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Módulo de análisis sintáctico que hace parte de SEÑAL: Programa para el análisis lingüístico y evaluación de composiciones de español.\n","\n","© Restrepo-Ramos\n","**2022**"],"metadata":{"id":"IQEZ7P96Usim"}},{"cell_type":"markdown","source":["# Módulo de complejidad sintáctica\n","\n","Este módulo permite medir la complejidad sintáctica de tus ensayos. Primero, el programa divide en unidades sintácticas tus oraciones utilizando un modelo pre-entrenado de español (más info [aquí](https://universaldependencies.org/)). El programa utiliza este modelo como muestra para analizar tus composiciones. Por último, el programa te presenta varias medidas de complejidad sintáctica de tus escritos. \n","\n","### Requisitos\n","No hay requisitos técnicos. Sólo presta atención a la presentación de tu instructor.\n","\n","### Materiales\n","1. Módelo pre-entrenado de español ***es.udpipe***\n","2. Tu ***muestra.txt***\n","\n","### Instrucciones\n","1. Ejecuta todas las líneas de código leyendo la descripción de cada funcionalidad del programa\n","3. interpreta los resultados de acuerdo a las distintas medidas de complejidad sintáctica"],"metadata":{"id":"6KaWfBL3LNOa"}},{"cell_type":"markdown","source":["**Paso 1**. Instalamos UDPipe\n","\n","UDPipe es el módulo que nos va a permitir dividir cada oración de tus composiciones en unidades sintácticas (i.e., *parsing*). El programa nos va a arrojar un archivo en formato ***.conllu*** "],"metadata":{"id":"MrnDn22GMfZO"}},{"cell_type":"code","source":["!pip install ufal.udpipe"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SZlpU9x5MYzy","executionInfo":{"status":"ok","timestamp":1646236513765,"user_tz":360,"elapsed":96416,"user":{"displayName":"Falcon Restrepo Ramos","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01792138933088691349"}},"outputId":"4f73d6b4-3848-4f01-f07b-27bd7b794bdf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ufal.udpipe\n","  Downloading ufal.udpipe-1.2.0.3.tar.gz (304 kB)\n","\u001b[K     |████████████████████████████████| 304 kB 5.2 MB/s \n","\u001b[?25hBuilding wheels for collected packages: ufal.udpipe\n","  Building wheel for ufal.udpipe (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ufal.udpipe: filename=ufal.udpipe-1.2.0.3-cp37-cp37m-linux_x86_64.whl size=5626658 sha256=8d077e2c359f22ef9235fcac7bb3297652c926de8fdbe75ab6f41e57c9c94f2d\n","  Stored in directory: /root/.cache/pip/wheels/b8/b5/8e/3da091629a21ce2d10bf90759d0cb034ba10a5cf7a01e83d64\n","Successfully built ufal.udpipe\n","Installing collected packages: ufal.udpipe\n","Successfully installed ufal.udpipe-1.2.0.3\n"]}]},{"cell_type":"markdown","source":["**Paso 2**\n","\n","Ejecutamos las siguiente línea de código. Aunque parece complicado, está parte del programa crea *definiciones* para que cuando subas tu composición, el programa pueda realizar la división sintáctica."],"metadata":{"id":"hpOu4xx9NjOj"}},{"cell_type":"code","source":["import sys\n","import ufal.udpipe\n","\n","class Model:\n","    def __init__(self, path):\n","        \"\"\"Load given model.\"\"\"\n","        self.model = ufal.udpipe.Model.load(path)\n","        if not self.model:\n","            raise Exception(\"Cannot load UDPipe model from file '%s'\" % path)\n","\n","    def tokenize(self, text):\n","        \"\"\"Tokenize the text and return list of ufal.udpipe.Sentence-s.\"\"\"\n","        tokenizer = self.model.newTokenizer(self.model.DEFAULT)\n","        if not tokenizer:\n","            raise Exception(\"The model does not have a tokenizer\")\n","        return self._read(text, tokenizer)\n","\n","    def read(self, text, in_format):\n","        \"\"\"Load text in the given format (conllu|horizontal|vertical) and return list of ufal.udpipe.Sentence-s.\"\"\"\n","        input_format = ufal.udpipe.InputFormat.newInputFormat(in_format)\n","        if not input_format:\n","            raise Exception(\"Cannot create input format '%s'\" % in_format)\n","        return self._read(text, input_format)\n","\n","    def _read(self, text, input_format):\n","        input_format.setText(text)\n","        error = ufal.udpipe.ProcessingError()\n","        sentences = []\n","\n","        sentence = ufal.udpipe.Sentence()\n","        while input_format.nextSentence(sentence, error):\n","            sentences.append(sentence)\n","            sentence = ufal.udpipe.Sentence()\n","        if error.occurred():\n","            raise Exception(error.message)\n","\n","        return sentences\n","\n","    def tag(self, sentence):\n","        \"\"\"Tag the given ufal.udpipe.Sentence (inplace).\"\"\"\n","        self.model.tag(sentence, self.model.DEFAULT)\n","\n","    def parse(self, sentence):\n","        \"\"\"Parse the given ufal.udpipe.Sentence (inplace).\"\"\"\n","        self.model.parse(sentence, self.model.DEFAULT)\n","\n","    def write(self, sentences, out_format):\n","        \"\"\"Write given ufal.udpipe.Sentence-s in the required format (conllu|horizontal|vertical).\"\"\"\n","\n","        output_format = ufal.udpipe.OutputFormat.newOutputFormat(out_format)\n","        output = ''\n","        for sentence in sentences:\n","            output += output_format.writeSentence(sentence)\n","        output += output_format.finishDocument()\n","\n","        return output"],"metadata":{"id":"MtwHKBWdNjTV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","**Paso 3**\n","\n","Subimos el módelo preentrenado de español\n","\n"],"metadata":{"id":"TtZiAbgNOUW0"}},{"cell_type":"code","source":["model = Model('es.udpipe')"],"metadata":{"id":"yJ24zUN5OUo0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Paso 4**\n","\n","Subimos nuestro ensayo a la memoria. Si tienes problemas con MAC cambia el encoding a: ISO-8859-1"],"metadata":{"id":"OnB_-38sOy9x"}},{"cell_type":"code","source":["ifile = open(\"muestra.txt\", mode='r', encoding='utf-8')\n","texto = ifile.read()\n","ifile.close()"],"metadata":{"id":"Iwog6ndhPA-Z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Paso 5**\n","\n","Utilizamos el modelo preentrenado y realizamos la división sintáctica de nuestras composiciones (*Parsing*)."],"metadata":{"id":"ihS-D0MyPOPR"}},{"cell_type":"code","source":["sentences = model.tokenize(texto)\n","for s in sentences:\n","    model.tag(s)\n","    model.parse(s)\n","conllu = model.write(sentences, \"conllu\")"],"metadata":{"id":"U3ApxMn0Pj5u"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Así luce una oración dividida sintácticamente por el programa:\n","\n","sent_id = 4\n","text = Por último, el campus no promueve la salud y el bienestar tanto como debería.\n","\n","1.\tPor\tpor\tADP\t_\t_\t2\tcase\t_\t_\n","2.\túltimo\túltimo\tNOUN\t_\tGender=Masc|Number=Sing\t7\tobl\t_\tSpaceAfter=No\n","3.\t,\t,\tPUNCT\t_\t_\t2\tpunct\t_\t_\n","4.\tel\tel\tDET\t_\tDefinite=Def|Gender=Masc|Number=Sing|PronType=Art\t5\tdet\t_\t_\n","5.\tcampus\tcampus\tNOUN\t_\tGender=Masc\t7\tnsubj\t_\t_\n","6.\tno\tno\tADV\t_\tPolarity=Neg\t7\tadvmod\t_\t_\n","7.\tpromueve\tpromover\tVERB\t_\tMood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\t0\troot\t_\t_\n","8.\tla\tel\tDET\t_\tDefinite=Def|Gender=Fem|Number=Sing|PronType=Art\t9\tdet\t_\t_\n","9.\tsalud\tsalud\tNOUN\t_\tGender=Fem|Number=Sing\t7\tobj\t_\t_\n","10.\ty\ty\tCCONJ\t_\t_\t12\tcc\t_\t_\n","11.\tel\tel\tDET\t_\tDefinite=Def|Gender=Masc|Number=Sing|PronType=Art\t12\tdet\t_\t_\n","12.\tbienestar\tbienestar\tVERB\t_\tGender=Masc|Number=Sing|VerbForm=Fin\t7\tconj\t_\t_\n","13.\ttanto\ttanto\tPRON\t_\tNumType=Card|PronType=Dem\t12\tobl\t_\t_\n","14.\tcomo\tcomo\tADP\t_\t_\t15\tcase\t_\t_\n","15.\tdebería\tdebería\tNOUN\t_\tGender=Fem|Number=Sing\t12\tobl\t_\tSpaceAfter=No\n","16.\t.\t.\tPUNCT\t_\t_\t7\tpunct\t_\t_\n","\n"],"metadata":{"id":"pLYAYfNBQS4C"}},{"cell_type":"markdown","source":["**Paso 6**\n","\n","Ahora vamos a contar la frecuencia de los siguientes indicadores sintacticos por oración:\n","\n","1. promedio de verbos por oración\n","2. promedio de palabras por oración\n","3. promedio de verbos auxiliares por oración\n","4. promedio de cláusulas relativas por oración\n","5. promedio de cláusulas adverbiales por oración\n","6. promedio general de cláusulas\n","7. promedio de t-units\n","8. promedio de conjunciones coordinativas\n","\n","Explicaré todo esto en clase.\n","\n"],"metadata":{"id":"0_PAxKJSQ9VL"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# for each of the sentences in the file\n","v = []\n","w = []\n","aux = []\n","rel = []\n","adv = []\n","clauses = []\n","t = []\n","conj = []\n","numsent = 0\n","\n","for sent in conllu.split('\\n\\n'): # aquí subimos el archivo .conllu que creamos\n","    sent_id = '' # the sentence id\n","    ntokens = 0 # number of words/tokens\n","    nverbs = 0\n","    naux = 0\n","    npunct = 0\n","    nrelclaus = 0\n","    finverb = 0\n","    nconj= 0\n","    tunits= 0\n","    advclaus = 0\n","    comp = 0\n","    numsent += 1\n","    if sent.strip() == '': # if there is no data in the sentence then skip it\n","        continue\n","    #for each of the lines in the sentence\n","    for line in sent.split('\\n'):\n","        # if the line contains the string 'sent_id', then sent the sent id to be the part after the '='\n","        if line.count('sent_id') > 0:\n","            sent_id = line.split('=')[1].strip()\n","            # if the line doesn't start with a # then increment the number of words\n","        if line[0] !='#':\n","            ntokens += 1\n","        #row = line.split('\\t')\n","        #if not row[1].outnum():\n","         #   npunct+=1\n","        if line.count('\\tPUNCT\\t') > 0:\n","            npunct += 1\n","        if line.count('\\tVERB\\t') > 0:\n","            nverbs +=1\n","        if line.count('\\tAUX\\t') > 0:\n","            naux +=1\n","        if line.count('\\tacl:relcl\\t') > 0:\n","            nrelclaus +=1\n","        if line.count('\\tadvcl\\t') > 0:\n","            advclaus += 1\n","        if line.count('\\tccomp\\t') > 0:\n","            comp += 1\n","        if line.count('\\tVerbForm=Fin\\t') > 0:\n","            finverb += 1\n","        if line.count('\\tCCONJ\\t') > 0:\n","            nconj += 1\n","        if line.count('\\tconj\\t') > 0 or line.count('\\tparataxis\\t'):\n","            tunits += 1\n","\n","    t_units = tunits  + 1\n","    nwords = ntokens-npunct\n","    #nclauses = nverbs + naux + nrelclaus - infverb -conj\n","    nclauses = nrelclaus + advclaus + t_units\n","\n","    # print out sentence id, number of words, and verbs per clause. This is for creating a table if desiredfor further analysis\n","    print('%s\\t%d\\t%d\\t%d\\t%d\\t%d\\t%d\\t%d\\t%d\\t%d\\t%d' % (sent_id, nwords, ntokens, npunct, nverbs, naux, nrelclaus, advclaus, nclauses, t_units, nconj))\n","\n","# here we are attaching the numbers in the counters to specific lists.\n","    v.append(nverbs)\n","    w.append(nwords)\n","    aux.append(naux)\n","    rel.append(nrelclaus)\n","    adv.append(advclaus)\n","    clauses.append(nclauses)\n","    t.append(t_units)\n","    conj.append(nconj)\n","\n","print('sent_id','nwords', 'ntokens', 'npunct', 'nverbs', 'naux', 'nrelclaus', 'advclaus','nclaus', 't_units', 'nconj')\n","# creating floats for the plots\n","vnum = [float(i) for i in v]\n","vmean = (sum(vnum)/(numsent-1))\n","wnum = [float(i) for i in w]\n","wmean = (sum(wnum)/(numsent-1))\n","auxnum = [float(i) for i in aux]\n","auxmean = (sum(auxnum)/(numsent-1))\n","relnum = [float(i) for i in rel]\n","relmean = (sum(relnum)/(numsent-1))\n","advnum = [float(i) for i in adv]\n","advmean = (sum(advnum)/(numsent-1))\n","clausenum = [float(i) for i in clauses]\n","clausemean = (sum(clausenum)/(numsent-1))\n","tnum = [float(i) for i in t]\n","tmean = (sum(tnum)/(numsent-1))\n","conjnum = [float(i) for i in conj]\n","conjmean = (sum(conjnum)/(numsent-1))\n"],"metadata":{"id":"ESYi_xJbTG6S"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Paso 7**\n","\n","Creamos la tabla con todos los resultados"],"metadata":{"id":"JeJNnwtLVGHB"}},{"cell_type":"code","source":["#creating a nice printing table\n","average = [vmean, wmean, auxmean, relmean, advmean, clausemean, tmean, conjmean]\n","names = [\"Verbos\", \"Palabras\", \"AUX\", \"Relativas\", \"Adverbiales\", \"Cláusulas\", \"T-Units\", \"Coordinación\"]\n","dct = {names[i]: average[i] for i in range(len(names))}\n","\n","print(\"\\nEste es el promedio de frecuencia de los indicadores sintácticos de tu glosario\")\n","print(\"Medida:\\t\\tPromedio de frecuencia:\")\n","for k, v in dct.items():\n","    print(k, '\\t', v)"],"metadata":{"id":"lvxdyzkCVMMb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Paso 8**\n","\n","Creamos un hermoso gráfico con el conteo y promedio de todos los indicadores sintácticos por oración."],"metadata":{"id":"fiU6MAy8VzYa"}},{"cell_type":"code","source":["data = [vmean, auxmean, relmean, advmean, clausemean, tmean, conjmean, wmean]\n","fig = plt.figure(figsize =(13, 7))\n","ax = fig.add_axes([0,0,1,1]) \n","indicadores = ['Verbos', 'VerbosAux', 'ClausuRel', 'ClausuAdv', 'Cláusulas', 'T-Units', 'Coordinación', 'Palabras']\n","ax.barh(indicadores, data)\n","plt.title('Promedio de indicadores sintácticos')\n","for index, value in enumerate(data):\n","    plt.text(value, index,\n","             str(value))\n","plt.show(fig)"],"metadata":{"id":"8mSLeaZ6YTOh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Ahora tú**\n","\n","Completa los espacios necesarios en las siguientes líneas de código para completar tu hermoso gráfico."],"metadata":{"id":"QseTfjCB2uUh"}},{"cell_type":"code","source":["# seleccionamos los datos del eje 'x' e 'y'\n","x = ['Verbos', 'VerbosAux', 'ClausuRel', 'ClausuAdv', 'Cláusulas', 'T-Units', 'Coordinación', 'Palabras']\n","y = [vmean, auxmean, relmean, advmean, clausemean, tmean, conjmean, wmean]\n","\n","# PARA HACER: ajusta el tamaño del gráfico\n","fig = plt.figure(figsize =(??, ?)) # COMPLETAR\n","\n","# PARA HACER: ajusta los colores. Puedes escoger más colores aquí: https://matplotlib.org/stable/gallery/color/named_colors.html\n","colors = ['gold', 'red', 'blue','slategray','hotpink', 'orchid', 'lime', 'deepskyblue']\n","plt.bar(x, y, color=colors)\n","\n","#PARA HACER: Escoge un título para tu gráfico\n","plt.title('Mi complejidad sintáctica en español') # tu título aquí\n","\n","# PARA HACER =¿Cuántos decimales quieres en cada barra?\n","for index, value in enumerate(y):\n","    plt.text(index, value, \n","             str(round(value, 3))) # ajusta el número de decimales\n","\n","# muestra el gráfic0\n","plt.show(fig)"],"metadata":{"id":"t3rS99aiA6c_"},"execution_count":null,"outputs":[]}]}